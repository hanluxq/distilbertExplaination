{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "HpCXxfYaJHeD"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers torch shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shap\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "data_path = 'textLabel.csv'\n",
    "labeled_path = 'output1.csv'\n",
    "promise_path = 'promise_nfr.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(promise_path,sep=';',usecols=[\"RequirementText\",\"NFR\"])"
   ],
   "metadata": {
    "id": "HhFJdDB_JJh9"
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# 分割数据集\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(data['RequirementText'], data['NFR'], test_size=0.2)\n",
    "train_text = train_text.iloc[:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DistilBert**"
   ],
   "metadata": {
    "id": "jqpP0q5AjspJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\").cuda()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZDnh98kRkep",
    "outputId": "983764b0-a997-49c2-c954-eea54497196e"
   },
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# use the custom function\n",
    "import scipy as sp\n",
    "def f(x):\n",
    "    tv = torch.tensor([tokenizer.encode(text, padding='max_length', max_length=128, truncation=True) for text in x]).cuda()\n",
    "    attention_mask = (tv!=0).type(torch.int64).cuda()\n",
    "    outputs = model(tv,attention_mask=attention_mask)[0].detach().cpu().numpy()\n",
    "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
    "    val = sp.special.logit(scores)\n",
    "    return val"
   ],
   "metadata": {
    "id": "lC1TatRUCTLN"
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "#计算重要特征，返回特征与重要性\n",
    "def important(shap_values):\n",
    "    reason = []\n",
    "    for ele in shap_values:\n",
    "        sum =0\n",
    "        for num in ele.values:\n",
    "            sum += abs(num[0])\n",
    "        avg = sum/len(ele.values)\n",
    "        res = []\n",
    "        for values,datas in zip(ele.values,ele.data):\n",
    "            cur = []\n",
    "            if abs(values[0])>=avg:\n",
    "                cur.append(datas)\n",
    "                cur.append(values[0])\n",
    "                res.append(cur)\n",
    "        reason.append(res)\n",
    "    return reason"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "7bk-cHksjy9l"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "#读取csv文件\n",
    "def read_file(file_name):\n",
    "    csv_file = open(file_name, encoding=\"utf-8\")\n",
    "    csv_reader_lines = csv.reader(csv_file)\n",
    "    raw_date = []\n",
    "    for i, line in enumerate(csv_reader_lines):\n",
    "        raw_date.append(line)\n",
    "    return raw_date"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "#读取标注文件，返回关注点\n",
    "def readLabel(file_path):\n",
    "    data = read_file(file_path)\n",
    "    words = []\n",
    "    labels = []\n",
    "    for ele in data[1:]:\n",
    "        #正则表达式提取每个文档的单词和对应的标签\n",
    "        features = []\n",
    "        label = []\n",
    "        #数据从第二行开始\n",
    "        for e in ele:\n",
    "            match_text = re.search(r'\"text\": \"(.*)\"', e.strip())\n",
    "            match_label = re.search(r'\"labels\": \\[\"(\\w+)\"\\]',e.strip())\n",
    "            if match_text:\n",
    "                features.append(match_text.group(1).strip())\n",
    "            if match_label:\n",
    "                label.append(match_label.group(1).strip())\n",
    "        words.append(features)\n",
    "        labels.append(label)\n",
    "    return words,labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def shapValues(data):\n",
    "    explainer = shap.Explainer(f,tokenizer,output_names=[\"FR\",\"NFR\"])\n",
    "    return explainer(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partition explainer: 51it [01:04,  1.55s/it]                        \n"
     ]
    }
   ],
   "source": [
    "concernsData = pd.read_csv(data_path,sep=',',usecols=[\"RequirementText\",\"Function\",\"Data\",\"Behavior\"])\n",
    "sample = concernsData['RequirementText']\n",
    "shap_values = shapValues(sample)\n",
    "importance = important(shap_values)\n",
    "words,labs = readLabel(labeled_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "评估特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "#检测异常特征\n",
    "def errCheck(importance,words):\n",
    "    errList = []\n",
    "    #遍历每个样例\n",
    "    for imp,con in zip(importance,words):\n",
    "        err = []\n",
    "        for e1 in imp:\n",
    "            #遍历重要特征，判断w是否是关注点，如果不是则异常\n",
    "            w = e1[0].strip()\n",
    "            #遍历关注点\n",
    "            if(any(w in item for item in con)==False) : err.append(w)\n",
    "        errList.append(err)\n",
    "    return errList"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "[['the',\n  'product',\n  'shall',\n  'that',\n  'can',\n  'the',\n  'product',\n  'must',\n  'that',\n  'are',\n  \"'\"],\n ['only', 'can', '.'],\n ['the', 'product', 'shall', 'have', 'to', 'to', '.'],\n ['the',\n  'product',\n  'shall',\n  'gui',\n  'based',\n  'monitoring',\n  'services',\n  '.',\n  'system'],\n ['the', 'will', 'by'],\n ['leads', 'that', 'system', 'and'],\n ['users', 'shall', 'be', 'able', 'to', 'nfl', 'and', '.'],\n ['when', 'the', 'the', 'of', 'sunk', 'on', 'the'],\n ['the',\n  'system',\n  'will',\n  'affected',\n  'parties',\n  'when',\n  'occur',\n  'including',\n  'but',\n  'and'],\n ['the', 'product', 'shall', 'whether', 'the', 'or'],\n ['the', 'will', 'by'],\n ['the', 'must', 'to', '.'],\n ['the', 'must', 'to', 'that', 'to', '.'],\n ['the', 'shall', 'based', 'on', 'the'],\n ['the', 'shall', 'that', 'can', '.', 'product', 'must', 'that', 'are', \"'\"],\n ['disputes',\n  'must',\n  'maintain',\n  'that',\n  '.',\n  'this',\n  'ensures',\n  'arise',\n  'with'],\n ['the', 'of', 'the', 'product', 'shall', 'or', '.'],\n ['shall',\n  'customers',\n  'longer',\n  'than',\n  'minutes',\n  '.',\n  'database',\n  'the',\n  'not',\n  'be',\n  'able',\n  'to',\n  'the',\n  'website',\n  '.'],\n ['the', 'will', 'an', 'for', 'un', 'erved', 'rooms', '.'],\n ['administrators', 'and', 'shall', 'be', 'to', 'single', 'to'],\n ['the',\n  'must',\n  'allow',\n  'to',\n  '(',\n  '(',\n  'ticket',\n  'retrieval',\n  'request',\n  'charge',\n  'back',\n  'notification',\n  ')'],\n ['the',\n  'system',\n  'shall',\n  'information',\n  'in',\n  'with',\n  'the',\n  's',\n  'information',\n  'policy',\n  '.'],\n ['the', 'product', 'shall', 'an', 'to', 'other', 'to', '.'],\n ['product', 'formula', 'shall', 'by', 'the', 'p', 'fe', 'sub', 'sy', '.'],\n ['the', 'system', 'shall', 'for', 'authorized', 'users'],\n ['the', 'leads', 'will', 'the', 'and', 'rights', 'to'],\n ['of',\n  'all',\n  'disputes',\n  'criteria',\n  'must',\n  'be',\n  'to',\n  'the',\n  '.',\n  'the',\n  'type',\n  'and',\n  '/',\n  'or',\n  'status',\n  'of',\n  'the',\n  'case',\n  'by',\n  'color',\n  '-',\n  'coding',\n  'item',\n  'in',\n  '.',\n  'and'],\n ['the', 'product', 'shall', 'from', '.'],\n ['when', 'a', 'product', 'the', 'players', 'that', 'the', '.'],\n ['product', 'shall', '.'],\n ['the', 'top', '1', 'of', 'the', 'will', 'that'],\n ['the',\n  'product',\n  'shall',\n  '.',\n  'shall',\n  'with',\n  'and',\n  '(',\n  'key',\n  'performance',\n  'indicators'],\n ['for',\n  'within',\n  'and',\n  'staff',\n  'members',\n  'able',\n  'which',\n  'that',\n  'offered',\n  '.'],\n ['the', 'will', 'provide', 'a', 'with', 'solutions', 'to', '.'],\n ['should',\n  'be',\n  'able',\n  'to',\n  'their',\n  'in',\n  'after',\n  'into',\n  'website',\n  '.'],\n ['the', 'product', 'shall', 'existing', '.'],\n ['if', 'the', 'as', 'product', 'shall', 'to', '.'],\n ['website', 'shall', 'and', 'card', 'before', '.'],\n ['must',\n  'search',\n  '.',\n  'the',\n  'search',\n  'method',\n  'must',\n  'include',\n  'the',\n  'ability',\n  'to',\n  'search',\n  'by',\n  '(',\n  '1',\n  ')',\n  'above',\n  'criteria',\n  'must',\n  'further',\n  'the',\n  'user',\n  'to',\n  'limit',\n  '(',\n  'ticket',\n  'retrieval',\n  'request',\n  'or',\n  'charge',\n  'back',\n  'notification',\n  ')',\n  'and'],\n ['the', 'product', 'shall', 'players', 'who', 'have', 'been', 'for'],\n ['the', 'shall', '.'],\n ['the', 'be', 'able', 'to', 'fa', 'cit', 'lity', 'estimate', '.'],\n ['students', 'to', 'shall', 'for', 'the', 'co', 's', 'study', '.'],\n ['the', 'shall', 'or', 'in'],\n ['the', 'shall', 'map', 'of', 'building', 'showing', '.'],\n ['will', 'customers', 'to', 'for', 'with', 'card', '.'],\n ['staff',\n  'members',\n  'shall',\n  'have',\n  'ability',\n  'to',\n  'relating',\n  'to',\n  'including',\n  'and',\n  'and',\n  '.'],\n ['the', 'shall', 'to', 'the', 'repair', 'facility', 'ratings', '.'],\n ['adjust',\n  'with',\n  'can',\n  'repair',\n  'facility',\n  '.',\n  'users',\n  'without',\n  'repair',\n  'facility',\n  '.'],\n ['the', 'shall', 'the', 'to', 'of', 'target', 'market', 'countries', '.']]"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errlist = errCheck(importance,words)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
